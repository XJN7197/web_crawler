"""
æ•°æ®åˆ†æå’ŒæŠ¥å‘Šç”Ÿæˆæ¨¡å—
"""
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from collections import Counter
from decimal import Decimal
import re

logger = logging.getLogger(__name__)

class DecimalEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†Decimalå’Œdatetimeç±»å‹"""
    
    def default(self, obj):
        if isinstance(obj, Decimal):
            # å°†Decimalè½¬æ¢ä¸ºfloatï¼Œä¿æŒæ•°å€¼ç²¾åº¦
            return float(obj)
        elif isinstance(obj, datetime):
            # å°†datetimeè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²
            return obj.isoformat()
        return super(DecimalEncoder, self).default(obj)

class WeiboDataAnalyzer:
    """å¾®åšæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, db_manager):
        self.db_manager = db_manager
    
    def generate_summary_report(self, keyword: str = "æé›¨çŠäº‹ä»¶") -> Dict[str, Any]:
        """ç”Ÿæˆæ•°æ®æ‘˜è¦æŠ¥å‘Š"""
        try:
            if not self.db_manager.connection:
                if not self.db_manager.connect():
                    return {}
            
            report = {
                'keyword': keyword,
                'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'basic_stats': self._get_basic_statistics(keyword),
                'time_distribution': self._get_time_distribution(keyword),
                'user_analysis': self._get_user_analysis(keyword),
                'content_analysis': self._get_content_analysis(keyword),
                'engagement_analysis': self._get_engagement_analysis(keyword),
                'geographic_analysis': self._get_geographic_analysis(keyword)
            }
            
            return report
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ‘˜è¦æŠ¥å‘Šå¤±è´¥: {e}")
            return {}
    
    def _get_basic_statistics(self, keyword: str) -> Dict[str, Any]:
        """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self.db_manager.connection.cursor() as cursor:
                # æ€»æ•°æ®é‡
                cursor.execute("""
                    SELECT COUNT(*) as total_count,
                           MIN(created_at) as earliest_post,
                           MAX(created_at) as latest_post,
                           AVG(reposts_count) as avg_reposts,
                           AVG(comments_count) as avg_comments,
                           AVG(attitudes_count) as avg_likes
                    FROM weibo_data 
                    WHERE keyword = %s
                """, (keyword,))
                
                result = cursor.fetchone()
                
                if result:
                    return {
                        'total_posts': result[0],
                        'earliest_post': result[1].strftime('%Y-%m-%d %H:%M:%S') if result[1] else None,
                        'latest_post': result[2].strftime('%Y-%m-%d %H:%M:%S') if result[2] else None,
                        'avg_reposts': round(result[3] or 0, 2),
                        'avg_comments': round(result[4] or 0, 2),
                        'avg_likes': round(result[5] or 0, 2)
                    }
                
                return {}
                
        except Exception as e:
            logger.error(f"è·å–åŸºç¡€ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def _get_time_distribution(self, keyword: str) -> Dict[str, Any]:
        """è·å–æ—¶é—´åˆ†å¸ƒåˆ†æ"""
        try:
            with self.db_manager.connection.cursor() as cursor:
                # æŒ‰æ—¥æœŸåˆ†å¸ƒ
                cursor.execute("""
                    SELECT DATE(created_at) as post_date, 
                           COUNT(*) as post_count
                    FROM weibo_data 
                    WHERE keyword = %s AND created_at IS NOT NULL
                    GROUP BY DATE(created_at)
                    ORDER BY post_date
                """, (keyword,))
                
                daily_data = cursor.fetchall()
                
                # æŒ‰å°æ—¶åˆ†å¸ƒ
                cursor.execute("""
                    SELECT HOUR(created_at) as post_hour, 
                           COUNT(*) as post_count
                    FROM weibo_data 
                    WHERE keyword = %s AND created_at IS NOT NULL
                    GROUP BY HOUR(created_at)
                    ORDER BY post_hour
                """, (keyword,))
                
                hourly_data = cursor.fetchall()
                
                return {
                    'daily_distribution': [
                        {
                            'date': row[0].strftime('%Y-%m-%d'),
                            'count': row[1]
                        } for row in daily_data
                    ],
                    'hourly_distribution': [
                        {
                            'hour': row[0],
                            'count': row[1]
                        } for row in hourly_data
                    ]
                }
                
        except Exception as e:
            logger.error(f"è·å–æ—¶é—´åˆ†å¸ƒå¤±è´¥: {e}")
            return {}
    
    def _get_user_analysis(self, keyword: str) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·åˆ†æ"""
        try:
            with self.db_manager.connection.cursor() as cursor:
                # æ´»è·ƒç”¨æˆ·TOP10
                cursor.execute("""
                    SELECT user_nick_name, 
                           COUNT(*) as post_count,
                           SUM(reposts_count) as total_reposts,
                           SUM(comments_count) as total_comments,
                           SUM(attitudes_count) as total_likes
                    FROM weibo_data 
                    WHERE keyword = %s AND user_nick_name IS NOT NULL
                    GROUP BY user_nick_name
                    ORDER BY post_count DESC
                    LIMIT 10
                """, (keyword,))
                
                top_users = cursor.fetchall()
                
                # è®¤è¯ç”¨æˆ·ç»Ÿè®¡
                cursor.execute("""
                    SELECT user_verified, COUNT(*) as count
                    FROM weibo_data 
                    WHERE keyword = %s
                    GROUP BY user_verified
                """, (keyword,))
                
                verified_stats = cursor.fetchall()
                
                return {
                    'top_active_users': [
                        {
                            'username': row[0],
                            'post_count': row[1],
                            'total_reposts': row[2] or 0,
                            'total_comments': row[3] or 0,
                            'total_likes': row[4] or 0
                        } for row in top_users
                    ],
                    'verified_distribution': {
                        'verified': next((row[1] for row in verified_stats if row[0]), 0),
                        'unverified': next((row[1] for row in verified_stats if not row[0]), 0)
                    }
                }
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _get_content_analysis(self, keyword: str) -> Dict[str, Any]:
        """è·å–å†…å®¹åˆ†æ"""
        try:
            with self.db_manager.connection.cursor() as cursor:
                # è·å–æ‰€æœ‰å†…å®¹è¿›è¡Œåˆ†æ
                cursor.execute("""
                    SELECT content, pic_num, isLongText, source
                    FROM weibo_data 
                    WHERE keyword = %s AND content IS NOT NULL
                """, (keyword,))
                
                contents = cursor.fetchall()
                
                # åˆ†æå†…å®¹ç‰¹å¾
                total_posts = len(contents)
                long_text_count = sum(1 for row in contents if row[2])
                has_image_count = sum(1 for row in contents if row[1] and row[1] > 0)
                
                # æ¥æºç»Ÿè®¡
                sources = [row[3] for row in contents if row[3]]
                source_counter = Counter(sources)
                
                # æå–è¯é¢˜æ ‡ç­¾
                all_hashtags = []
                for row in contents:
                    if row[0]:
                        hashtags = re.findall(r'#([^#]+)#', row[0])
                        all_hashtags.extend(hashtags)
                
                hashtag_counter = Counter(all_hashtags)
                
                return {
                    'total_analyzed': total_posts,
                    'long_text_ratio': round(long_text_count / total_posts * 100, 2) if total_posts > 0 else 0,
                    'image_ratio': round(has_image_count / total_posts * 100, 2) if total_posts > 0 else 0,
                    'top_sources': [
                        {'source': source, 'count': count}
                        for source, count in source_counter.most_common(10)
                    ],
                    'top_hashtags': [
                        {'hashtag': hashtag, 'count': count}
                        for hashtag, count in hashtag_counter.most_common(10)
                    ]
                }
                
        except Exception as e:
            logger.error(f"è·å–å†…å®¹åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _get_engagement_analysis(self, keyword: str) -> Dict[str, Any]:
        """è·å–äº’åŠ¨åˆ†æ"""
        try:
            with self.db_manager.connection.cursor() as cursor:
                # äº’åŠ¨æ•°æ®ç»Ÿè®¡
                cursor.execute("""
                    SELECT 
                        SUM(reposts_count) as total_reposts,
                        SUM(comments_count) as total_comments,
                        SUM(attitudes_count) as total_likes,
                        MAX(reposts_count) as max_reposts,
                        MAX(comments_count) as max_comments,
                        MAX(attitudes_count) as max_likes
                    FROM weibo_data 
                    WHERE keyword = %s
                """, (keyword,))
                
                result = cursor.fetchone()
                
                # é«˜äº’åŠ¨å¾®åšTOP10
                cursor.execute("""
                    SELECT content, user_nick_name, reposts_count, comments_count, attitudes_count,
                           (reposts_count + comments_count + attitudes_count) as total_engagement
                    FROM weibo_data 
                    WHERE keyword = %s
                    ORDER BY total_engagement DESC
                    LIMIT 10
                """, (keyword,))
                
                top_engagement = cursor.fetchall()
                
                if result:
                    return {
                        'total_engagement': {
                            'reposts': result[0] or 0,
                            'comments': result[1] or 0,
                            'likes': result[2] or 0
                        },
                        'max_engagement': {
                            'reposts': result[3] or 0,
                            'comments': result[4] or 0,
                            'likes': result[5] or 0
                        },
                        'top_engagement_posts': [
                            {
                                'content': row[0][:100] + '...' if row[0] and len(row[0]) > 100 else row[0],
                                'user': row[1],
                                'reposts': row[2] or 0,
                                'comments': row[3] or 0,
                                'likes': row[4] or 0,
                                'total': row[5] or 0
                            } for row in top_engagement
                        ]
                    }
                
                return {}
                
        except Exception as e:
            logger.error(f"è·å–äº’åŠ¨åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _get_geographic_analysis(self, keyword: str) -> Dict[str, Any]:
        """è·å–åœ°ç†åˆ†æ"""
        try:
            with self.db_manager.connection.cursor() as cursor:
                # IPä½ç½®ç»Ÿè®¡
                cursor.execute("""
                    SELECT ip_location, COUNT(*) as count
                    FROM weibo_data 
                    WHERE keyword = %s AND ip_location IS NOT NULL AND ip_location != ''
                    GROUP BY ip_location
                    ORDER BY count DESC
                    LIMIT 20
                """, (keyword,))
                
                ip_locations = cursor.fetchall()
                
                # åœ°ç†ä½ç½®ç»Ÿè®¡
                cursor.execute("""
                    SELECT geo_detail_title, COUNT(*) as count
                    FROM weibo_data 
                    WHERE keyword = %s AND geo_detail_title IS NOT NULL AND geo_detail_title != ''
                    GROUP BY geo_detail_title
                    ORDER BY count DESC
                    LIMIT 20
                """, (keyword,))
                
                geo_locations = cursor.fetchall()
                
                return {
                    'ip_distribution': [
                        {'location': row[0], 'count': row[1]}
                        for row in ip_locations
                    ],
                    'geo_distribution': [
                        {'location': row[0], 'count': row[1]}
                        for row in geo_locations
                    ]
                }
                
        except Exception as e:
            logger.error(f"è·å–åœ°ç†åˆ†æå¤±è´¥: {e}")
            return {}
    
    def export_report_to_json(self, report: Dict[str, Any], filename: str = None) -> str:
        """å¯¼å‡ºæŠ¥å‘Šä¸ºJSONæ–‡ä»¶"""
        try:
            if not filename:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"data/weibo_analysis_report_{timestamp}.json"
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            import os
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2, cls=DecimalEncoder)
            
            logger.info(f"æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
            return filename
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæŠ¥å‘Šå¤±è´¥: {e}")
            logger.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
            logger.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            return ""
    
    
    def print_summary(self, report: Dict[str, Any]):
        """æ‰“å°æŠ¥å‘Šæ‘˜è¦"""
        try:
            print("\n" + "="*60)
            print(f"å¾®åšæ•°æ®åˆ†ææŠ¥å‘Š - {report.get('keyword', 'æœªçŸ¥å…³é”®è¯')}")
            print(f"ç”Ÿæˆæ—¶é—´: {report.get('generated_at', 'æœªçŸ¥')}")
            print("="*60)
            
            # åŸºç¡€ç»Ÿè®¡
            basic = report.get('basic_stats', {})
            if basic:
                print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
                print(f"  æ€»å¾®åšæ•°: {basic.get('total_posts', 0):,}")
                print(f"  æ—¶é—´èŒƒå›´: {basic.get('earliest_post', 'æœªçŸ¥')} ~ {basic.get('latest_post', 'æœªçŸ¥')}")
                print(f"  å¹³å‡è½¬å‘: {basic.get('avg_reposts', 0)}")
                print(f"  å¹³å‡è¯„è®º: {basic.get('avg_comments', 0)}")
                print(f"  å¹³å‡ç‚¹èµ: {basic.get('avg_likes', 0)}")
            
            # ç”¨æˆ·åˆ†æ
            user_analysis = report.get('user_analysis', {})
            if user_analysis:
                print(f"\nğŸ‘¥ ç”¨æˆ·åˆ†æ:")
                verified = user_analysis.get('verified_distribution', {})
                print(f"  è®¤è¯ç”¨æˆ·: {verified.get('verified', 0)}")
                print(f"  æ™®é€šç”¨æˆ·: {verified.get('unverified', 0)}")
                
                top_users = user_analysis.get('top_active_users', [])[:5]
                if top_users:
                    print(f"  æ´»è·ƒç”¨æˆ·TOP5:")
                    for i, user in enumerate(top_users, 1):
                        print(f"    {i}. {user.get('username', 'æœªçŸ¥')} ({user.get('post_count', 0)}æ¡)")
            
            # å†…å®¹åˆ†æ
            content = report.get('content_analysis', {})
            if content:
                print(f"\nğŸ“ å†…å®¹åˆ†æ:")
                print(f"  é•¿æ–‡æœ¬æ¯”ä¾‹: {content.get('long_text_ratio', 0)}%")
                print(f"  å«å›¾ç‰‡æ¯”ä¾‹: {content.get('image_ratio', 0)}%")
                
                top_hashtags = content.get('top_hashtags', [])[:5]
                if top_hashtags:
                    print(f"  çƒ­é—¨è¯é¢˜TOP5:")
                    for i, tag in enumerate(top_hashtags, 1):
                        print(f"    {i}. #{tag.get('hashtag', 'æœªçŸ¥')}# ({tag.get('count', 0)}æ¬¡)")
            
            # äº’åŠ¨åˆ†æ
            engagement = report.get('engagement_analysis', {})
            if engagement:
                total_eng = engagement.get('total_engagement', {})
                print(f"\nğŸ’¬ äº’åŠ¨ç»Ÿè®¡:")
                print(f"  æ€»è½¬å‘æ•°: {total_eng.get('reposts', 0):,}")
                print(f"  æ€»è¯„è®ºæ•°: {total_eng.get('comments', 0):,}")
                print(f"  æ€»ç‚¹èµæ•°: {total_eng.get('likes', 0):,}")
            
            print("="*60)
            
        except Exception as e:
            logger.error(f"æ‰“å°æ‘˜è¦å¤±è´¥: {e}")