"""
æŠ–éŸ³çˆ¬è™«åŠŸèƒ½æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æŠ–éŸ³æ•°æ®çˆ¬å–åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import os
import sys
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from multi_platform_crawler import MultiPlatformCrawler
from config.settings import PLATFORM_CONFIG
from utils.logger import setup_logger

def test_douyin_crawler():
    """æµ‹è¯•æŠ–éŸ³çˆ¬è™«åŠŸèƒ½"""
    logger = setup_logger()
    
    print("="*60)
    print("æŠ–éŸ³çˆ¬è™«åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    try:
        # åˆ›å»ºæŠ–éŸ³çˆ¬è™«å®ä¾‹
        print("1. åˆ›å»ºæŠ–éŸ³çˆ¬è™«å®ä¾‹...")
        crawler = MultiPlatformCrawler(platform='douyin')
        print("âœ“ æŠ–éŸ³çˆ¬è™«å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("\n2. åˆå§‹åŒ–ç³»ç»Ÿ...")
        if crawler.initialize():
            print("âœ“ ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âœ— ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return False
        
        # æµ‹è¯•é…ç½®åŠ è½½
        print("\n3. æµ‹è¯•é…ç½®åŠ è½½...")
        platform_config = PLATFORM_CONFIG.get('douyin')
        if platform_config:
            print(f"âœ“ å¹³å°é…ç½®åŠ è½½æˆåŠŸ: {platform_config['name']}")
            print(f"  - æœç´¢URL: {platform_config['search_url']}")
            print(f"  - ç”¨æˆ·ä»£ç†: {platform_config['user_agent'][:50]}...")
        else:
            print("âœ— å¹³å°é…ç½®åŠ è½½å¤±è´¥")
            return False
        
        # æµ‹è¯•çˆ¬è™«åˆ›å»º
        print("\n4. æµ‹è¯•çˆ¬è™«å®ä¾‹...")
        spider = crawler.spider
        if spider:
            print(f"âœ“ çˆ¬è™«å®ä¾‹åˆ›å»ºæˆåŠŸ: {type(spider).__name__}")
        else:
            print("âœ— çˆ¬è™«å®ä¾‹åˆ›å»ºå¤±è´¥")
            return False
        
        # æµ‹è¯•æ•°æ®åº“è¿æ¥
        print("\n5. æµ‹è¯•æ•°æ®åº“è¿æ¥...")
        db_manager = crawler.db_manager
        if db_manager.connection:
            print("âœ“ æ•°æ®åº“è¿æ¥æˆåŠŸ")
            
            # æ£€æŸ¥æŠ–éŸ³æ•°æ®è¡¨æ˜¯å¦å­˜åœ¨
            try:
                with db_manager.connection.cursor() as cursor:
                    cursor.execute("SHOW TABLES LIKE 'douyin_data'")
                    result = cursor.fetchone()
                    if result:
                        print("âœ“ æŠ–éŸ³æ•°æ®è¡¨å­˜åœ¨")
                    else:
                        print("âœ— æŠ–éŸ³æ•°æ®è¡¨ä¸å­˜åœ¨")
                        return False
            except Exception as e:
                print(f"âœ— æ£€æŸ¥æ•°æ®è¡¨å¤±è´¥: {e}")
                return False
        else:
            print("âœ— æ•°æ®åº“è¿æ¥å¤±è´¥")
            return False
        
        # æµ‹è¯•å°è§„æ¨¡æ•°æ®çˆ¬å–
        print("\n6. æµ‹è¯•æ•°æ®çˆ¬å–åŠŸèƒ½...")
        print("æ­£åœ¨è¿›è¡Œå°è§„æ¨¡æµ‹è¯•çˆ¬å–ï¼ˆ1é¡µæ•°æ®ï¼‰...")
        
        test_keyword = "ç¾é£Ÿ"  # ä½¿ç”¨é€šç”¨å…³é”®è¯è¿›è¡Œæµ‹è¯•
        success = crawler.crawl_data(keyword=test_keyword, max_pages=1)
        
        if success:
            print("âœ“ æ•°æ®çˆ¬å–æµ‹è¯•æˆåŠŸ")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = crawler.get_statistics()
            current_stats = stats['current_session']
            
            print(f"  - çˆ¬å–å…³é”®è¯: {test_keyword}")
            print(f"  - æ€»çˆ¬å–æ•°é‡: {current_stats['total_crawled']}")
            print(f"  - æˆåŠŸä¿å­˜: {current_stats['success_count']}")
            print(f"  - å¤±è´¥æ•°é‡: {current_stats['error_count']}")
            
            if current_stats['total_crawled'] > 0:
                print("âœ“ æˆåŠŸè·å–åˆ°æŠ–éŸ³æ•°æ®")
            else:
                print("âš  æœªè·å–åˆ°æ•°æ®ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–åçˆ¬è™«é™åˆ¶")
        else:
            print("âœ— æ•°æ®çˆ¬å–æµ‹è¯•å¤±è´¥")
            return False
        
        # æµ‹è¯•æ•°æ®æŸ¥è¯¢
        print("\n7. æµ‹è¯•æ•°æ®æŸ¥è¯¢åŠŸèƒ½...")
        try:
            with db_manager.connection.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) FROM douyin_data")
                count = cursor.fetchone()[0]
                print(f"âœ“ æ•°æ®åº“ä¸­å…±æœ‰ {count} æ¡æŠ–éŸ³æ•°æ®")
                
                if count > 0:
                    cursor.execute("SELECT _id, content, author, publish_time FROM douyin_data LIMIT 1")
                    sample = cursor.fetchone()
                    if sample:
                        print("âœ“ æ•°æ®æ ·æœ¬:")
                        print(f"  - ID: {sample[0]}")
                        print(f"  - å†…å®¹: {sample[1][:50]}...")
                        print(f"  - ä½œè€…: {sample[2]}")
                        print(f"  - å‘å¸ƒæ—¶é—´: {sample[3]}")
        except Exception as e:
            print(f"âœ— æ•°æ®æŸ¥è¯¢å¤±è´¥: {e}")
            return False
        
        print("\n" + "="*60)
        print("âœ“ æŠ–éŸ³çˆ¬è™«åŠŸèƒ½æµ‹è¯•å®Œæˆ - æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        print("="*60)
        
        return True
        
    except Exception as e:
        print(f"\nâœ— æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.error(f"æŠ–éŸ³çˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    finally:
        # æ¸…ç†èµ„æº
        try:
            crawler.cleanup()
        except:
            pass

def test_platform_comparison():
    """æµ‹è¯•å¹³å°å¯¹æ¯”åŠŸèƒ½"""
    print("\n" + "="*60)
    print("å¹³å°å¯¹æ¯”æµ‹è¯•")
    print("="*60)
    
    platforms = ['weibo', 'douyin']
    
    for platform in platforms:
        print(f"\næµ‹è¯• {PLATFORM_CONFIG[platform]['name']} å¹³å°:")
        try:
            crawler = MultiPlatformCrawler(platform=platform)
            if crawler.initialize():
                print(f"âœ“ {PLATFORM_CONFIG[platform]['name']} åˆå§‹åŒ–æˆåŠŸ")
                
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                stats = crawler.get_statistics()
                db_stats = stats.get('database_stats', {})
                
                if platform == 'weibo':
                    table_name = 'weibo_data'
                else:
                    table_name = 'douyin_data'
                
                try:
                    with crawler.db_manager.connection.cursor() as cursor:
                        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                        count = cursor.fetchone()[0]
                        print(f"  - æ•°æ®åº“è®°å½•æ•°: {count}")
                except:
                    print(f"  - æ•°æ®åº“è®°å½•æ•°: 0")
                
                crawler.cleanup()
            else:
                print(f"âœ— {PLATFORM_CONFIG[platform]['name']} åˆå§‹åŒ–å¤±è´¥")
        except Exception as e:
            print(f"âœ— {PLATFORM_CONFIG[platform]['name']} æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æŠ–éŸ³çˆ¬è™«åŠŸèƒ½æµ‹è¯•...")
    
    # æµ‹è¯•æŠ–éŸ³çˆ¬è™«åŠŸèƒ½
    douyin_success = test_douyin_crawler()
    
    # æµ‹è¯•å¹³å°å¯¹æ¯”
    test_platform_comparison()
    
    # è¾“å‡ºæœ€ç»ˆç»“æœ
    print("\n" + "="*60)
    if douyin_success:
        print("ğŸ‰ æŠ–éŸ³çˆ¬è™«åŠŸèƒ½æµ‹è¯•å…¨éƒ¨é€šè¿‡!")
        print("ç³»ç»Ÿå·²å‡†å¤‡å¥½è¿›è¡ŒæŠ–éŸ³æ•°æ®çˆ¬å–ã€‚")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("python multi_platform_crawler.py --platform douyin --keyword 'æœç´¢å…³é”®è¯' --pages 5")
    else:
        print("âŒ æŠ–éŸ³çˆ¬è™«åŠŸèƒ½æµ‹è¯•å¤±è´¥!")
        print("è¯·æ£€æŸ¥é…ç½®å’Œç½‘ç»œè¿æ¥åé‡è¯•ã€‚")
    print("="*60)
    
    return 0 if douyin_success else 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)